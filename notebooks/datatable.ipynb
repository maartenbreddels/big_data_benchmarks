{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:41:51.231990Z",
     "start_time": "2020-01-23T18:41:51.192426Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.benchmarks_utils import benchmark, get_results\n",
    "from src.datatable_utils import *\n",
    "from src.config import repetitions\n",
    "import gc\n",
    "name = 'datatable'\n",
    "data_path = '/data/yellow_taxi_2009_2015_f32.hdf5'\n",
    "data = read_file(None, data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:40:19.671690Z",
     "start_time": "2020-01-23T18:39:22.710870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done benchmarks on all data\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate memory of size 9384463416[errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9da048fec0b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# filtered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mfilterd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/xdssio/big_data_benchmarks/notebooks/src/datatable_utils.py\u001b[0m in \u001b[0;36mfilter_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     78\u001b[0m               \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropoff_longitude\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlong_min\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropoff_longitude\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlong_max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m               \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropoff_latitude\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlat_min\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropoff_latitude\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlat_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexpr_filter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate memory of size 9384463416[errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "benchmarks = {}\n",
    "benchmarks['read_file']= benchmark(read_file, df=data, data_path=data_path, repetitions=repetitions)\n",
    "benchmarks['length']= benchmark(read_file, df=data, data_path=data_path, repetitions=repetitions)\n",
    "benchmarks['mean']= benchmark(mean, data, repetitions=repetitions)\n",
    "benchmarks['standard deviation']= benchmark(standard_deviation, data, repetitions=repetitions)\n",
    "benchmarks['mean of sum']= benchmark(sum_columns, data, repetitions=repetitions)\n",
    "benchmarks['mean of product']= benchmark(product_columns, data, repetitions=repetitions)\n",
    "benchmarks['mean of complicated arithmetic operation'] = np.nan\n",
    "# benchmarks['arithmetic operation']= benchmark(complicated_arithmetic_operation, data, repetitions=repetitions)\n",
    "benchmarks['value counts'] = np.nan\n",
    "# benchmarks['value counts']= benchmark(value_counts, data, repetitions=repetitions)\n",
    "benchmarks['groupby statistics']= benchmark(groupby_statistics, data, repetitions=repetitions)\n",
    "# benchmarks['filter']= benchmark(filter_data, data, repetitions=repetitions)\n",
    "print(f\"cleaned {gc.collect()} mb\")\n",
    "benchmarks['join'] = benchmark(join, data, repetitions=repetitions, other=groupby_statistics(data))\n",
    "print(f\"Done benchmarks on all data\")\n",
    "\n",
    "# filtered\n",
    "# try:\n",
    "filterd = filter_data(data)\n",
    "del data\n",
    "\n",
    "# print(f\"Prepare filtered data and deleted {gc.collect()} MB\")\n",
    "benchmarks['filtered mean'] = benchmark(mean, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered standard deviation'] = benchmark(standard_deviation, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered mean of sum'] = benchmark(mean_of_sum , filterd, repetitions=repetitions)\n",
    "benchmarks['filtered mean of product'] = benchmark(mean_of_product , filterd, repetitions=repetitions)\n",
    "benchmarks['filtered mean of complicated arithmetic operation'] = benchmark(complicated_arithmetic_operation, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered value counts'] = benchmark(value_counts, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered groupby statistics'] = benchmark(groupby_statistics, filterd, repetitions=repetitions)\n",
    "benchmarks['filtered join'] = benchmark(join, filterd, repetitions=repetitions, other=groupby_statistics(filterd))\n",
    "print(f\"Done benchmarks on filterd data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T18:41:54.778632Z",
     "start_time": "2020-01-23T18:41:54.756476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datatable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>0.007547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read_file</th>\n",
       "      <td>0.006116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.424518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard deviation</th>\n",
       "      <td>6.944938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum columns</th>\n",
       "      <td>13.227248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product columns</th>\n",
       "      <td>12.676934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arithmetic operation</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value counts</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groupby statistics</th>\n",
       "      <td>40.010559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join</th>\n",
       "      <td>8.225986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      datatable\n",
       "length                 0.007547\n",
       "read_file              0.006116\n",
       "mean                   5.424518\n",
       "standard deviation     6.944938\n",
       "sum columns           13.227248\n",
       "product columns       12.676934\n",
       "arithmetic operation        NaN\n",
       "value counts                NaN\n",
       "groupby statistics    40.010559\n",
       "join                   8.225986"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_results(benchmarks, name)\n",
    "# results.to_csv(results_path)\n",
    "results#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
